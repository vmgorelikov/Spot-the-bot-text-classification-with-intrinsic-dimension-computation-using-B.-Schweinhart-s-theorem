Spot the bot: text classification with intrinsic dimension computation using B. Schweinhart's theorem

This repository contains the code and some of the data for my term paper.

# How to use
1. Download the files from this repository.
   
2. Make sure you have all of the required modules installed.

```pip install numpy spacy sklearn tqdm```

```python -m spacy.ru.download ru_core_news_sm```

3. MST-Clustering should be installed with

```pip install git+https://github.com/whiteroomlz/mst-clustering.git```

4. See code in question if something goes wrong.
   
5. Run ```python classifier.py <the text you would like to classify> [the model to be used] [the dictionary to be used]```

# Files by sections of the paper
## Sections 4, 5.

```bambara_processor.py``` — the processor for Bambara texts.

## Sections 4, 6

```corpora/``` — the corpora used in the study, truncated to 100 MB due to the file size limit on GitHub. Should be used to check the models' accuracy.

```dictionaries/Russian_dict_SVD_100.npy``` — the dictionary used in the study, cropped to the actually used dimensions.

```text_to_vectors.py``` — the script for converting tokens into a time series. Only used as an imported module.

```vectors_to_schweinhart.py``` — the script for estimating intrinsic dimensions of a time series. Only used as an imported module.

```texts_to_schweinhart.py``` — the script which was used to compute the intrinsic dimensions for all texts.

```batches/``` — the batches with sets of ten computed intrinsic dimensions computed for each text with names of format ```<max alpha>_<number of alphas>_<batch number>_X.pkl.npy``` and the corresponding text classes with names of format  ```<max alpha>_<number of alphas>_<batch number>_y.pkl.npy```

## Section 7
```train.py``` — the script which was used for training and evaluating the 42 models.

```classifier.py``` — the script which can be used to classify texts. It will probably not spot a text generated by a LLM of today.
